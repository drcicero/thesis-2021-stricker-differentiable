\section{Forward Mode Differentiation}

Forward mode differentiation by hand is straight forward and also translates well into code by sticking to our existing knowledge about symbolic differentiation \todo{define symbolic differentiation?}. Essentially we want to go through every operation recursively and replace it with its derivative.


\subsection{Literal approach with macros}

If you take the last sentence literally you could now go the long and hard way (which we did), learn metaprogramming and implement it exactly by replacing expressions with their derivative. This approach looks rather ugly at first sight but after ignoring the boilerplate one can see that it just boils down to recursive pattern matching of code which works pretty well in Scala 3:
\begin{lstlisting}[language=scala]
    def d(t: Expr[Term])(using Quotes): Expr[Term] = t match
        case '{ ($l: Term) + ($r: Term) } =>    // l + r
            '{ ${ d(l) } + ${ d(r) } }          // d(l) + d(r)
        case '{ ($l: Term) * ($r: Term) } =>    // l * r
            '{ $l * ${ d(r) } + ${ d(l) } * $r }// l * d(r) + d(l) * d(r)
        case '{ X } => '{ 1 }                   // variable
        case '{ $v: V } => '{ 0 }               // constant
\end{lstlisting}
As this was just a small experiment we leave this here without much explanation for now. In fact we wouldn't even need macros and could just write our term with algebraic data types and recursively match them at runtime to implement this approach. This would reduce the boilerplate in comparison to the macro-implementation above.


\subsection{Operator overloading with dual numbers}
\todo{Highly inspired by lantern paper (or github)}
Rewriting code that way has one problem. We loose the actual result of our formula and only get the derivative (or we would have to calculate both separately). Instead we could use a structure that consists of two values, the normal result of the operation and its derivative. Such a construct is called a "dual number" \todo{link Wikipedia or maybe a paper?} and could look like this:
\lstscala{implementation/DualNumber.scala}{3}{3}
To implement an operation on these we have to define the actual computation and additionally how to compute the derivative:
\lstscala{implementation/DualNumber.scala}{3}{12}
As we can see this comes down to translating mathematic symbolic differentiation rules into code (lines 4 and 9). How to define constants and the variable which we differentiate our function with respect to \todo{englisch spaek you can?} also comes naturally:
\lstscala{implementation/DualNumber.scala}{14}{15}
Differentiation of a function $f$ at $x = 3$ could then look like this:
\lstscala{implementation/DualNumber.scala}{18}{24}


\subsection{Static typing taken too far (Or: Let the compiler code for you)}
To explain the following approach we first have to look at match types \cite{matchTypesScala3}which are essentially functions but at type level.
